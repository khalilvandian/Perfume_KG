{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z2Q5FfqkJ3xN",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Dataset analysis & RLTK components construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "fTlKyPqCJ3xO",
    "outputId": "f8d02d9d-601c-4c75-e48e-842d5dba3de7",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rltk\n",
      "  Using cached rltk-2.0.0a20-py3-none-any.whl (81 kB)\n",
      "Requirement already satisfied: dask>=0.19.2 in d:\\anaconda\\lib\\site-packages (from rltk) (2022.7.0)\n",
      "Requirement already satisfied: Cython>=0.28.0 in d:\\anaconda\\lib\\site-packages (from rltk) (0.29.32)\n",
      "Requirement already satisfied: pandas>=1.2.0 in d:\\anaconda\\lib\\site-packages (from rltk) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.17.0 in d:\\anaconda\\lib\\site-packages (from rltk) (1.21.5)\n",
      "Requirement already satisfied: distributed>=1.23 in d:\\anaconda\\lib\\site-packages (from rltk) (2022.7.0)\n",
      "Collecting pyrallel.lib\n",
      "  Using cached pyrallel.lib-0.0.10-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: scipy>=1.1.0 in d:\\anaconda\\lib\\site-packages (from rltk) (1.9.1)\n",
      "Requirement already satisfied: matplotlib>=2.0.0 in d:\\anaconda\\lib\\site-packages (from rltk) (3.5.2)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\anaconda\\lib\\site-packages (from dask>=0.19.2->rltk) (21.3)\n",
      "Requirement already satisfied: toolz>=0.8.2 in d:\\anaconda\\lib\\site-packages (from dask>=0.19.2->rltk) (0.11.2)\n",
      "Requirement already satisfied: cloudpickle>=1.1.1 in d:\\anaconda\\lib\\site-packages (from dask>=0.19.2->rltk) (2.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in d:\\anaconda\\lib\\site-packages (from dask>=0.19.2->rltk) (6.0)\n",
      "Requirement already satisfied: partd>=0.3.10 in d:\\anaconda\\lib\\site-packages (from dask>=0.19.2->rltk) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=0.6.0 in d:\\anaconda\\lib\\site-packages (from dask>=0.19.2->rltk) (2022.7.1)\n",
      "Requirement already satisfied: tornado<6.2,>=6.0.3 in d:\\anaconda\\lib\\site-packages (from distributed>=1.23->rltk) (6.1)\n",
      "Requirement already satisfied: jinja2 in d:\\anaconda\\lib\\site-packages (from distributed>=1.23->rltk) (2.11.3)\n",
      "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in d:\\anaconda\\lib\\site-packages (from distributed>=1.23->rltk) (2.4.0)\n",
      "Requirement already satisfied: urllib3 in d:\\anaconda\\lib\\site-packages (from distributed>=1.23->rltk) (1.26.11)\n",
      "Requirement already satisfied: psutil>=5.0 in d:\\anaconda\\lib\\site-packages (from distributed>=1.23->rltk) (5.9.0)\n",
      "Requirement already satisfied: locket>=1.0.0 in d:\\anaconda\\lib\\site-packages (from distributed>=1.23->rltk) (1.0.0)\n",
      "Requirement already satisfied: msgpack>=0.6.0 in d:\\anaconda\\lib\\site-packages (from distributed>=1.23->rltk) (1.0.3)\n",
      "Requirement already satisfied: click>=6.6 in d:\\anaconda\\lib\\site-packages (from distributed>=1.23->rltk) (8.0.4)\n",
      "Requirement already satisfied: tblib>=1.6.0 in d:\\anaconda\\lib\\site-packages (from distributed>=1.23->rltk) (1.7.0)\n",
      "Requirement already satisfied: zict>=0.1.3 in d:\\anaconda\\lib\\site-packages (from distributed>=1.23->rltk) (2.1.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in d:\\anaconda\\lib\\site-packages (from matplotlib>=2.0.0->rltk) (9.2.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\anaconda\\lib\\site-packages (from matplotlib>=2.0.0->rltk) (4.25.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\anaconda\\lib\\site-packages (from matplotlib>=2.0.0->rltk) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\anaconda\\lib\\site-packages (from matplotlib>=2.0.0->rltk) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\anaconda\\lib\\site-packages (from matplotlib>=2.0.0->rltk) (1.4.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in d:\\anaconda\\lib\\site-packages (from matplotlib>=2.0.0->rltk) (3.0.9)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\anaconda\\lib\\site-packages (from pandas>=1.2.0->rltk) (2022.1)\n",
      "Collecting multiprocess>=0.70\n",
      "  Downloading multiprocess-0.70.14-py39-none-any.whl (132 kB)\n",
      "     -------------------------------------- 132.9/132.9 kB 2.6 MB/s eta 0:00:00\n",
      "Collecting typing>=3.6\n",
      "  Using cached typing-3.7.4.3-py3-none-any.whl\n",
      "Requirement already satisfied: dill>=0.3 in d:\\anaconda\\lib\\site-packages (from pyrallel.lib->rltk) (0.3.4)\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\lib\\site-packages (from click>=6.6->distributed>=1.23->rltk) (0.4.5)\n",
      "Collecting dill>=0.3\n",
      "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
      "     -------------------------------------- 110.5/110.5 kB 6.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six>=1.5 in d:\\anaconda\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=2.0.0->rltk) (1.16.0)\n",
      "Requirement already satisfied: heapdict in d:\\anaconda\\lib\\site-packages (from zict>=0.1.3->distributed>=1.23->rltk) (1.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in d:\\anaconda\\lib\\site-packages (from jinja2->distributed>=1.23->rltk) (2.0.1)\n",
      "Installing collected packages: typing, dill, multiprocess, pyrallel.lib, rltk\n",
      "  Attempting uninstall: dill\n",
      "    Found existing installation: dill 0.3.4\n",
      "    Uninstalling dill-0.3.4:\n",
      "      Successfully uninstalled dill-0.3.4\n",
      "Successfully installed dill-0.3.6 multiprocess-0.70.14 pyrallel.lib-0.0.10 rltk-2.0.0a20 typing-3.7.4.3\n"
     ]
    }
   ],
   "source": [
    "# !pip install rltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K8fyiwzJJ3xP",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Task 1-1. Construct RLTK Datasets\n",
    "\n",
    "First, you need define how a single entry would like for each type of record (for each dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "We7cQGTRJ3xP",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import rltk\n",
    "import csv\n",
    "\n",
    "# You can use this tokenizer in case you need to manipulate some data\n",
    "tokenizer = rltk.tokenizer.crf_tokenizer.crf_tokenizer.CrfTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "T3Q_rPqmJ3xP",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Feel free to add more columns here for use in record linkage.\n",
    "'''\n",
    "\n",
    "class Perfume(rltk.Record):\n",
    "    def __init__(self, raw_object):\n",
    "        super().__init__(raw_object)\n",
    "#         self.name = ''\n",
    "\n",
    "    @rltk.cached_property\n",
    "    def id(self):\n",
    "        return self.raw_object['_id']\n",
    "    \n",
    "    @rltk.cached_property\n",
    "    def node_id(self):\n",
    "        return self.raw_object['node_id']\n",
    "\n",
    "    @rltk.cached_property\n",
    "    def name(self):\n",
    "        return self.raw_object['name']\n",
    "\n",
    "    @rltk.cached_property\n",
    "    def brand(self):\n",
    "        return self.raw_object['brand']\n",
    "    \n",
    "    @rltk.cached_property\n",
    "    def url(self):\n",
    "        return self.raw_object['url']\n",
    "    \n",
    "    @rltk.cached_property\n",
    "    def price(self):\n",
    "        return self.raw_object['price']\n",
    "    \n",
    "    @rltk.cached_property\n",
    "    def scent(self):\n",
    "        return self.raw_object['scent']\n",
    "\n",
    "# class NobleRecord(rltk.Record):\n",
    "#     def __init__(self, raw_object):\n",
    "#         super().__init__(raw_object)\n",
    "#         self.name = ''\n",
    "\n",
    "#     @rltk.cached_property\n",
    "#     def id(self):\n",
    "#         return self.raw_object['ID']\n",
    "\n",
    "#     @rltk.cached_property\n",
    "#     def name_string(self):\n",
    "#         return self.raw_object['Title']\n",
    "    \n",
    "#     @rltk.cached_property\n",
    "#     def name_tokens(self):\n",
    "#         return set(tokenizer.tokenize(self.name_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "cZ2VHWnwJ3xQ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dir_ = '../data/entity_linking/'\n",
    "file1 = dir_ + 'allNodes.csv'\n",
    "file2 = dir_ + 'allNodes.csv'\n",
    "\n",
    "ds1 = rltk.Dataset(rltk.CSVReader(open(file1, encoding='utf-8')),record_class=Perfume)\n",
    "ds2 = rltk.Dataset(rltk.CSVReader(open(file2, encoding ='utf-8')),record_class=Perfume)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4XHgnuhJJ3xQ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "You can load your csv files into RLTK using this method:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KIylouixJ3xQ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "And we can inspect a few entries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "5CUrpjGTJ3xQ",
    "outputId": "498d3b0e-a742-4740-8751-3a348661e5d0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  id node_id                   name   brand  \\\n",
      "0  0      n1                   No.5  chanel   \n",
      "1  1      n2          Chance Chanel  chanel   \n",
      "2  2      n3            CHANEL No 5  chanel   \n",
      "3  3      n4            Chanel No 5  chanel   \n",
      "4  4      n5  Chanel Bleu De Chanel  chanel   \n",
      "\n",
      "                                                 url   price   scent  \n",
      "0  https://www.amazon.com//sspa/click?ie=UTF8&spc...      30   Apple  \n",
      "1  https://www.amazon.com//Chance-Chanel-Tendre-W...  148.98    NULL  \n",
      "2  https://www.amazon.com//CHANEL-No-Eau-Parfum-1...    19.9    NULL  \n",
      "3  https://www.amazon.com//Chanel-Parfum-Spray-Pe...  133.89   Fresh  \n",
      "4  https://www.amazon.com//Chanel-Toilette-Spray-...     108  Citrus  \n",
      "\n",
      "*********************************************\n",
      "\n",
      "  id node_id                   name   brand  \\\n",
      "0  0      n1                   No.5  chanel   \n",
      "1  1      n2          Chance Chanel  chanel   \n",
      "2  2      n3            CHANEL No 5  chanel   \n",
      "3  3      n4            Chanel No 5  chanel   \n",
      "4  4      n5  Chanel Bleu De Chanel  chanel   \n",
      "\n",
      "                                                 url   price   scent  \n",
      "0  https://www.amazon.com//sspa/click?ie=UTF8&spc...      30   Apple  \n",
      "1  https://www.amazon.com//Chance-Chanel-Tendre-W...  148.98    NULL  \n",
      "2  https://www.amazon.com//CHANEL-No-Eau-Parfum-1...    19.9    NULL  \n",
      "3  https://www.amazon.com//Chanel-Parfum-Spray-Pe...  133.89   Fresh  \n",
      "4  https://www.amazon.com//Chanel-Toilette-Spray-...     108  Citrus  \n"
     ]
    }
   ],
   "source": [
    "# print some entries\n",
    "print(ds1.generate_dataframe().head(5))\n",
    "print('\\n*********************************************\\n')\n",
    "print(ds2.generate_dataframe().head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MB0HHqDpJ3xR"
   },
   "source": [
    "### Task 1-2. Blocking\n",
    "\n",
    "First, we'll load dev set to evaluate both blocking (Task 1-2) and entity linking (Task 1-3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "YfGah0DhJ3xR",
    "outputId": "762cc35a-df00-46f4-fb8f-0200a600bd71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names are: goodreads.ID, barnes_and_nobles.ID, label\n",
      "Processed 297 lines.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<rltk.evaluation.trial.Trial at 0x1f36d23d0d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dev_set_file = dir_ + 'dev.csv'\n",
    "# dev = []\n",
    "# with open(dev_set_file, encoding='utf-8', errors=\"replace\") as csv_file:\n",
    "#     csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "#     line_count = 0\n",
    "#     for row in csv_reader:\n",
    "#         if len(row) <= 1:\n",
    "#             continue\n",
    "#         if line_count == 0:\n",
    "#             columns = row\n",
    "#             line_count += 1\n",
    "#         else:\n",
    "#             dev.append(row)\n",
    "#     print(f'Column names are: {\", \".join(columns)}')\n",
    "#     print(f'Processed {len(dev)} lines.')\n",
    "\n",
    "# gt = rltk.GroundTruth()\n",
    "# for row in dev:    \n",
    "#     r1 = ds1.get_record(row[0])\n",
    "#     r2  = ds2.get_record(row[1])\n",
    "#     if row[-1] == '1':\n",
    "#         gt.add_positive(r1.raw_object['ID'], r2.raw_object['ID'])\n",
    "#     else:\n",
    "#         gt.add_negative(r1.raw_object['ID'], r2.raw_object['ID'])\n",
    "\n",
    "# rltk.Trial(gt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aJ07ud86J3xR"
   },
   "source": [
    "Then, you can build your own blocking techniques and evaluate it.\n",
    "\n",
    "Hint:\n",
    "\n",
    "- What is the total number of pairs without blocking? \n",
    "- what is the number of paris with blocking?\n",
    "- After blocking, how many \"correct\" (matched) pairs presented in dev set?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OCpi3AqZJ3xR",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Task 1-3. Entity Linking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "98xt8o9kJ3xS",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Here are 2 example functions for field (attribute) similarity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "oQ3jFoFSJ3xS",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def name_string_similarity_1(r1, r2):\n",
    "    ''' Example dummy similiary function '''\n",
    "    s1 = r1.name\n",
    "    s2 = r2.name\n",
    "    \n",
    "    return rltk.jaro_winkler_similarity(s1, s2)\n",
    "    \n",
    "def name_string_similarity_2(r1, r2):\n",
    "    ''' Example dummy similiary function '''\n",
    "    s1 = r1.name\n",
    "    s2 = r2.name\n",
    "    \n",
    "    if s1 == s2:\n",
    "        return 1\n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9peeajHNJ3xS",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Here's how you can combine multiple similarity functions into a single weightened scoring function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "fGf52bBcJ3xS",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# threshold value to determine if we are confident the record match\n",
    "MY_TRESH = 0.6 # this number is just an example, you need to change it\n",
    "\n",
    "# entity linkage scoring function\n",
    "def rule_based_method(r1, r2):\n",
    "    score_1 = name_string_similarity_1(r1, r2)\n",
    "    score_2 = name_string_similarity_2(r1, r2)\n",
    "    \n",
    "    total = 0.7 * score_1 + 0.3 * score_2\n",
    "    \n",
    "    # return two values: boolean if they match or not, float to determine confidence\n",
    "    return total > MY_TRESH, total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WLbrTPamJ3xS",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Lets run some candidates using the ground-truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "Xo9-fdimJ3xS",
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # trial = rltk.Trial(gt)\n",
    "# # candidate_pairs = rltk.get_record_pairs(ds1, ds2, ground_truth=gt)\n",
    "# candidate_pairs = rltk.get_record_pairs(ds1, ds2)\n",
    "# count = 0\n",
    "# for r1, r2 in candidate_pairs:\n",
    "#     if r1.brand == r2.brand:\n",
    "#         result, confidence = rule_based_method(r1, r2)\n",
    "# #     trial.add_result(r1, r2, result, confidence)\n",
    "#         print(result, confidence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tqhybHyKJ3xS",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now lets evaluate our trial results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "7PJlbaUcJ3xS",
    "outputId": "bce6863d-2ee2-4b6d-90cd-90029742cd60",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# trial.evaluate()\n",
    "# print('Trial statistics based on Ground-Truth from development set data:')\n",
    "# print(f'tp: {trial.true_positives:.06f} [{len(trial.true_positives_list)}]')\n",
    "# print(f'fp: {trial.false_positives:.06f} [{len(trial.false_positives_list)}]')\n",
    "# print(f'tn: {trial.true_negatives:.06f} [{len(trial.true_negatives_list)}]')\n",
    "# print(f'fn: {trial.false_negatives:.06f} [{len(trial.false_negatives_list)}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "ximXdpDkJ3xS",
    "outputId": "dde53833-1f7b-4b4e-9f0a-66682b58bde0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# trial.f_measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "32c-kCWqJ3xT",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Save Test predictions\n",
    "You will be evaluated on dev and test predictions, over a hidden ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "t1qkfFDrJ3xT",
    "outputId": "8bed2f96-0065-4893-e9ac-21d8e44ced53",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# test_set_file = dir_ + 'test.csv'\n",
    "# test = []\n",
    "# with open(test_set_file, encoding='utf-8', errors=\"replace\") as csv_file:\n",
    "#     csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "#     line_count = 0\n",
    "#     for row in csv_reader:\n",
    "#         if len(row) <= 1:\n",
    "#             continue\n",
    "#         if line_count == 0:\n",
    "#             columns = row\n",
    "#             line_count += 1\n",
    "#         else:\n",
    "#             test.append(row)\n",
    "#     print(f'Column names are: {\", \".join(columns)}')\n",
    "#     print(f'Processed {len(test)} lines.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "UfC2TKISJ3xT",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "predictions = []\n",
    "\n",
    "\n",
    "candidate_pairs = rltk.get_record_pairs(ds1, ds2)\n",
    "for r1, r2 in candidate_pairs:\n",
    "    if r1.brand == r2.brand:\n",
    "        result, confidence = rule_based_method(r1, r2)\n",
    "#         print(result, confidence)\n",
    "        predictions.append([r1.node_id, r1.name, r1.url, r2.node_id, r2.name, r2.url, result, confidence])\n",
    "    \n",
    "# for id1, id2 in test:\n",
    "#     r1 = ds1.get_record(id1)\n",
    "#     r2  = ds2.get_record(id2)\n",
    "#     result, confidence = rule_based_method(r1, r2)\n",
    "#     predictions.append((r1.id, r2.id, result, confidence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "4UCWB2Q6J3xT",
    "outputId": "5a2d2a1d-3c4a-4d87-da59-89cc94ee6f8b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569775, 2739, 2739)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions), len(ds1.generate_dataframe()), len(ds2.generate_dataframe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "UnxUzg4WJ3xT",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# with open(dir_ + 'predictions.csv', mode='w', encoding='utf-8') as file:\n",
    "#     writer = csv.writer(file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "#     for row in predictions:\n",
    "#         writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "dvnuzp4OJ3xU",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "predictions_df = pd.DataFrame(data=np.array(predictions), columns=['node_id1', 'name1', 'url1',\\\n",
    "                                                                   'node_id2', 'name2', 'url2',\\\n",
    "                                                                   'result', 'confidence'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df.to_csv(dir_ + 'samAs_predictions.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
